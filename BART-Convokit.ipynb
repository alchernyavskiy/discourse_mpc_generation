{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install convokit torch==1.5.0 transformers==4.16.2 datasets==1.18.3 rouge_score google rouge==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Corpus, download\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(filename=download(\"reddit-coarse-discourse-corpus\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_ids = corpus.get_conversation_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.get_conversations_dataframe().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(conversation_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utter_df = corpus.get_utterances_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utter_df['text_len'] = utter_df.text.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utter_df['text_len'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "utter_df.to_pickle('data/convokit/utter_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9483/9483 [02:22<00:00, 66.55it/s]\n"
     ]
    }
   ],
   "source": [
    "max_s, max_u = 0, 0\n",
    "for conv_id in tqdm(conversation_ids):\n",
    "    conv_data = utter_df[utter_df.conversation_id == conv_id]\n",
    "    max_s = max(max_s, len(conv_data.speaker.unique()))\n",
    "    max_u = max(max_u, conv_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 41)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_s, max_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/convokit/utter_df.pkl', 'rb') as f:\n",
    "    utter_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_raw_data(conv_df):\n",
    "    speakers = {}\n",
    "    utters = {}\n",
    "    result = []\n",
    "    for id, row in zip(conv_df.index, conv_df.values):\n",
    "        utters[id] = 'u' + str(len(utters) + 1)\n",
    "        speaker = row[0]\n",
    "        if speaker not in speakers:\n",
    "            speakers[speaker] = 's' + str(len(speakers) + 1)\n",
    "        prev_id = row[1]\n",
    "        item = [utters[id], speakers[speaker], 'unk', 'bos', row[3]]  # unk - none; bos - для начала\n",
    "        if row[2] != None:\n",
    "            item[2] = row[2]\n",
    "        if prev_id != None:\n",
    "            if prev_id not in utters:\n",
    "                prev_id = conv_df.index[0]\n",
    "            item[3] = utters[prev_id]\n",
    "        for i in range(len(item) - 1):\n",
    "            item[i] = '<' + item[i] + '>'\n",
    "        result.append(item)\n",
    "    return result\n",
    "\n",
    "\n",
    "def construct_generation_examples(utter_df, conv_id):\n",
    "    conv_data = utter_df[utter_df.conversation_id == conv_id][['speaker', 'reply_to', 'meta.majority_type', 'text']]\n",
    "    train_examples = []\n",
    "    preproc_utter = construct_raw_data(conv_data)\n",
    "    for k in range(1, len(preproc_utter) - 1):\n",
    "        cur_context = ' </s> '.join([' '.join(item) for item in preproc_utter[:k]])\n",
    "        u_text = [el[-1] for el in preproc_utter[:k] if el[0] == preproc_utter[k][3]]\n",
    "        u_text = u_text[0] if len(u_text) > 0 else ''\n",
    "        cur_context += f' </s> {preproc_utter[k][1]} {preproc_utter[k][3]} {u_text}'\n",
    "        cur_context = re.sub(r'\\s+', ' ', cur_context)\n",
    "        cur_utter = ' '.join([preproc_utter[k][2], preproc_utter[k][4]])\n",
    "        train_examples.append([cur_context, cur_utter])\n",
    "    return train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_id = 't3_1yjwii' #'t3_1cduyx'\n",
    "conv_data = utter_df[utter_df.conversation_id == conv_id][['speaker', 'reply_to', 'meta.majority_type', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<u1>',\n",
       "  '<s1>',\n",
       "  '<announcement>',\n",
       "  '<bos>',\n",
       "  '[Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines)\\n\\n[Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0)\\n\\n**Notes:**\\n\\n---\\n\\n**IP:** 31.3.251.181\\n\\n**Version:** 1.7.4\\n\\n**Whitelist off:** 15 minutes before start\\n\\n**Game start:** 14:00 UTC\\n\\n**Game length:** 1.5 hours\\n\\n**Endgame:** Meetup at 0,0\\n\\n**Player Slots:** 30\\n\\n**Gamemode/Scenario:** FFA\\n\\n**PvP/iPvP:** 2nd day\\n\\n**Stealing:** Yes\\n\\n**Stalking:** No\\n\\n**Towering:** No\\n\\n**GHeads:** Yes\\n\\n**Absorption:** Yes\\n\\n**Nether:** On\\n\\n**Allies:** No\\n\\n**Additional Info:**\\n\\n---\\n\\n**Server Info:**\\n\\n**Ram:** 2.5GB\\n\\n**Located in:** London\\n\\n**Slots:** 30'],\n",
       " ['<u2>', '<s2>', '<unk>', '<u1>', \"I'll be there^h^y^p^e\"],\n",
       " ['<u3>', '<s3>', '<unk>', '<u1>', 'finally a game with nether!'],\n",
       " ['<u4>',\n",
       "  '<s4>',\n",
       "  '<elaboration>',\n",
       "  '<u1>',\n",
       "  'I dont like doing solos but ill give it a try but i end up suiciding cause im doing good but i fall off a ravine or something :P'],\n",
       " ['<u5>', '<s5>', '<question>', '<u1>', 'Is pigmen spawning enabled?'],\n",
       " ['<u6>', '<s1>', '<answer>', '<u5>', 'Pigmen will spawn in the nether :)'],\n",
       " ['<u7>', '<s6>', '<question>', '<u1>', 'When whitelist is off?'],\n",
       " ['<u8>', '<s4>', '<question>', '<u1>', 'allies allowed?'],\n",
       " ['<u9>', '<s1>', '<answer>', '<u8>', 'No allies'],\n",
       " ['<u10>',\n",
       "  '<s7>',\n",
       "  '<appreciation>',\n",
       "  '<u1>',\n",
       "  \"I'll be there too :D Thanks in advance for hosting!\"],\n",
       " ['<u11>',\n",
       "  '<s8>',\n",
       "  '<negativereaction>',\n",
       "  '<u1>',\n",
       "  'So fucking stupid, it said im not whitelisted then its full complete bullshit.'],\n",
       " ['<u12>',\n",
       "  '<s9>',\n",
       "  '<other>',\n",
       "  '<u11>',\n",
       "  \"Settle down there, lil' buddy. Plenty more games to play.\"],\n",
       " ['<u13>',\n",
       "  '<s1>',\n",
       "  '<elaboration>',\n",
       "  '<u11>',\n",
       "  'You have to join at exactly 15 minutes before match start\\n'],\n",
       " ['<u14>',\n",
       "  '<s10>',\n",
       "  '<unk>',\n",
       "  '<u1>',\n",
       "  \"Bad hosting in my mind Potions weren't nerfed one bit i got 2 hit when i had full prot 2 on kinda upset\"],\n",
       " ['<u15>', '<s8>', '<appreciation>', '<u1>', 'Loooking forward to it :3!']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "construct_raw_data(conv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>meta.majority_type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t3_1yjwii</th>\n",
       "      <td>TheQyet</td>\n",
       "      <td>None</td>\n",
       "      <td>announcement</td>\n",
       "      <td>[Universal Rules](http://www.reddit.com/r/uhcc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_cflroww</th>\n",
       "      <td>Azye</td>\n",
       "      <td>t3_1yjwii</td>\n",
       "      <td>None</td>\n",
       "      <td>I'll be there^h^y^p^e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_cfls9du</th>\n",
       "      <td>Andibadia</td>\n",
       "      <td>t3_1yjwii</td>\n",
       "      <td>None</td>\n",
       "      <td>finally a game with nether!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_cflrv4g</th>\n",
       "      <td>Djydoesmc</td>\n",
       "      <td>t3_1yjwii</td>\n",
       "      <td>elaboration</td>\n",
       "      <td>I dont like doing solos but ill give it a try ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_cfls3gt</th>\n",
       "      <td>DarkAngelKing2</td>\n",
       "      <td>t3_1yjwii</td>\n",
       "      <td>question</td>\n",
       "      <td>Is pigmen spawning enabled?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_cfls487</th>\n",
       "      <td>TheQyet</td>\n",
       "      <td>t1_cfls3gt</td>\n",
       "      <td>answer</td>\n",
       "      <td>Pigmen will spawn in the nether :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_cfls3j7</th>\n",
       "      <td>Enderdoood</td>\n",
       "      <td>t3_1yjwii</td>\n",
       "      <td>question</td>\n",
       "      <td>When whitelist is off?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_cfls6j9</th>\n",
       "      <td>Djydoesmc</td>\n",
       "      <td>t3_1yjwii</td>\n",
       "      <td>question</td>\n",
       "      <td>allies allowed?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_cfls937</th>\n",
       "      <td>TheQyet</td>\n",
       "      <td>t1_cfls6j9</td>\n",
       "      <td>answer</td>\n",
       "      <td>No allies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_cflsa6t</th>\n",
       "      <td>JoeStar1000</td>\n",
       "      <td>t3_1yjwii</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>I'll be there too :D Thanks in advance for hos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_cflscg4</th>\n",
       "      <td>Bubblez97</td>\n",
       "      <td>t3_1yjwii</td>\n",
       "      <td>negativereaction</td>\n",
       "      <td>So fucking stupid, it said im not whitelisted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_cflsepx</th>\n",
       "      <td>AladarTheHun</td>\n",
       "      <td>t1_cflscg4</td>\n",
       "      <td>other</td>\n",
       "      <td>Settle down there, lil' buddy. Plenty more gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_cflt2dk</th>\n",
       "      <td>TheQyet</td>\n",
       "      <td>t1_cflscg4</td>\n",
       "      <td>elaboration</td>\n",
       "      <td>You have to join at exactly 15 minutes before ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_cfltokc</th>\n",
       "      <td>cmk950003</td>\n",
       "      <td>t3_1yjwii</td>\n",
       "      <td>None</td>\n",
       "      <td>Bad hosting in my mind Potions weren't nerfed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_cflrpg5</th>\n",
       "      <td>Bubblez97</td>\n",
       "      <td>t3_1yjwii</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>Loooking forward to it :3!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   speaker    reply_to meta.majority_type  \\\n",
       "id                                                          \n",
       "t3_1yjwii          TheQyet        None       announcement   \n",
       "t1_cflroww            Azye   t3_1yjwii               None   \n",
       "t1_cfls9du       Andibadia   t3_1yjwii               None   \n",
       "t1_cflrv4g       Djydoesmc   t3_1yjwii        elaboration   \n",
       "t1_cfls3gt  DarkAngelKing2   t3_1yjwii           question   \n",
       "t1_cfls487         TheQyet  t1_cfls3gt             answer   \n",
       "t1_cfls3j7      Enderdoood   t3_1yjwii           question   \n",
       "t1_cfls6j9       Djydoesmc   t3_1yjwii           question   \n",
       "t1_cfls937         TheQyet  t1_cfls6j9             answer   \n",
       "t1_cflsa6t     JoeStar1000   t3_1yjwii       appreciation   \n",
       "t1_cflscg4       Bubblez97   t3_1yjwii   negativereaction   \n",
       "t1_cflsepx    AladarTheHun  t1_cflscg4              other   \n",
       "t1_cflt2dk         TheQyet  t1_cflscg4        elaboration   \n",
       "t1_cfltokc       cmk950003   t3_1yjwii               None   \n",
       "t1_cflrpg5       Bubblez97   t3_1yjwii       appreciation   \n",
       "\n",
       "                                                         text  \n",
       "id                                                             \n",
       "t3_1yjwii   [Universal Rules](http://www.reddit.com/r/uhcc...  \n",
       "t1_cflroww                              I'll be there^h^y^p^e  \n",
       "t1_cfls9du                        finally a game with nether!  \n",
       "t1_cflrv4g  I dont like doing solos but ill give it a try ...  \n",
       "t1_cfls3gt                        Is pigmen spawning enabled?  \n",
       "t1_cfls487                 Pigmen will spawn in the nether :)  \n",
       "t1_cfls3j7                             When whitelist is off?  \n",
       "t1_cfls6j9                                    allies allowed?  \n",
       "t1_cfls937                                          No allies  \n",
       "t1_cflsa6t  I'll be there too :D Thanks in advance for hos...  \n",
       "t1_cflscg4  So fucking stupid, it said im not whitelisted ...  \n",
       "t1_cflsepx  Settle down there, lil' buddy. Plenty more gam...  \n",
       "t1_cflt2dk  You have to join at exactly 15 minutes before ...  \n",
       "t1_cfltokc  Bad hosting in my mind Potions weren't nerfed ...  \n",
       "t1_cflrpg5                         Loooking forward to it :3!  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = construct_generation_examples(utter_df, conv_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<u1> <s1> <announcement> <bos> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30 </s> <s2> <u1> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30',\n",
       "  \"<unk> I'll be there^h^y^p^e\"],\n",
       " [\"<u1> <s1> <announcement> <bos> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30 </s> <u2> <s2> <unk> <u1> I'll be there^h^y^p^e </s> <s3> <u1> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30\",\n",
       "  '<unk> finally a game with nether!'],\n",
       " [\"<u1> <s1> <announcement> <bos> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30 </s> <u2> <s2> <unk> <u1> I'll be there^h^y^p^e </s> <u3> <s3> <unk> <u1> finally a game with nether! </s> <s4> <u1> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30\",\n",
       "  '<elaboration> I dont like doing solos but ill give it a try but i end up suiciding cause im doing good but i fall off a ravine or something :P'],\n",
       " [\"<u1> <s1> <announcement> <bos> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30 </s> <u2> <s2> <unk> <u1> I'll be there^h^y^p^e </s> <u3> <s3> <unk> <u1> finally a game with nether! </s> <u4> <s4> <elaboration> <u1> I dont like doing solos but ill give it a try but i end up suiciding cause im doing good but i fall off a ravine or something :P </s> <s5> <u1> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30\",\n",
       "  '<question> Is pigmen spawning enabled?'],\n",
       " [\"<u1> <s1> <announcement> <bos> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30 </s> <u2> <s2> <unk> <u1> I'll be there^h^y^p^e </s> <u3> <s3> <unk> <u1> finally a game with nether! </s> <u4> <s4> <elaboration> <u1> I dont like doing solos but ill give it a try but i end up suiciding cause im doing good but i fall off a ravine or something :P </s> <u5> <s5> <question> <u1> Is pigmen spawning enabled? </s> <s1> <u5> Is pigmen spawning enabled?\",\n",
       "  '<answer> Pigmen will spawn in the nether :)'],\n",
       " [\"<u1> <s1> <announcement> <bos> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30 </s> <u2> <s2> <unk> <u1> I'll be there^h^y^p^e </s> <u3> <s3> <unk> <u1> finally a game with nether! </s> <u4> <s4> <elaboration> <u1> I dont like doing solos but ill give it a try but i end up suiciding cause im doing good but i fall off a ravine or something :P </s> <u5> <s5> <question> <u1> Is pigmen spawning enabled? </s> <u6> <s1> <answer> <u5> Pigmen will spawn in the nether :) </s> <s6> <u1> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30\",\n",
       "  '<question> When whitelist is off?'],\n",
       " [\"<u1> <s1> <announcement> <bos> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30 </s> <u2> <s2> <unk> <u1> I'll be there^h^y^p^e </s> <u3> <s3> <unk> <u1> finally a game with nether! </s> <u4> <s4> <elaboration> <u1> I dont like doing solos but ill give it a try but i end up suiciding cause im doing good but i fall off a ravine or something :P </s> <u5> <s5> <question> <u1> Is pigmen spawning enabled? </s> <u6> <s1> <answer> <u5> Pigmen will spawn in the nether :) </s> <u7> <s6> <question> <u1> When whitelist is off? </s> <s4> <u1> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30\",\n",
       "  '<question> allies allowed?'],\n",
       " [\"<u1> <s1> <announcement> <bos> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30 </s> <u2> <s2> <unk> <u1> I'll be there^h^y^p^e </s> <u3> <s3> <unk> <u1> finally a game with nether! </s> <u4> <s4> <elaboration> <u1> I dont like doing solos but ill give it a try but i end up suiciding cause im doing good but i fall off a ravine or something :P </s> <u5> <s5> <question> <u1> Is pigmen spawning enabled? </s> <u6> <s1> <answer> <u5> Pigmen will spawn in the nether :) </s> <u7> <s6> <question> <u1> When whitelist is off? </s> <u8> <s4> <question> <u1> allies allowed? </s> <s1> <u8> allies allowed?\",\n",
       "  '<answer> No allies'],\n",
       " [\"<u1> <s1> <announcement> <bos> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30 </s> <u2> <s2> <unk> <u1> I'll be there^h^y^p^e </s> <u3> <s3> <unk> <u1> finally a game with nether! </s> <u4> <s4> <elaboration> <u1> I dont like doing solos but ill give it a try but i end up suiciding cause im doing good but i fall off a ravine or something :P </s> <u5> <s5> <question> <u1> Is pigmen spawning enabled? </s> <u6> <s1> <answer> <u5> Pigmen will spawn in the nether :) </s> <u7> <s6> <question> <u1> When whitelist is off? </s> <u8> <s4> <question> <u1> allies allowed? </s> <u9> <s1> <answer> <u8> No allies </s> <s7> <u1> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30\",\n",
       "  \"<appreciation> I'll be there too :D Thanks in advance for hosting!\"],\n",
       " [\"<u1> <s1> <announcement> <bos> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30 </s> <u2> <s2> <unk> <u1> I'll be there^h^y^p^e </s> <u3> <s3> <unk> <u1> finally a game with nether! </s> <u4> <s4> <elaboration> <u1> I dont like doing solos but ill give it a try but i end up suiciding cause im doing good but i fall off a ravine or something :P </s> <u5> <s5> <question> <u1> Is pigmen spawning enabled? </s> <u6> <s1> <answer> <u5> Pigmen will spawn in the nether :) </s> <u7> <s6> <question> <u1> When whitelist is off? </s> <u8> <s4> <question> <u1> allies allowed? </s> <u9> <s1> <answer> <u8> No allies </s> <u10> <s7> <appreciation> <u1> I'll be there too :D Thanks in advance for hosting! </s> <s8> <u1> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30\",\n",
       "  '<negativereaction> So fucking stupid, it said im not whitelisted then its full complete bullshit.'],\n",
       " [\"<u1> <s1> <announcement> <bos> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30 </s> <u2> <s2> <unk> <u1> I'll be there^h^y^p^e </s> <u3> <s3> <unk> <u1> finally a game with nether! </s> <u4> <s4> <elaboration> <u1> I dont like doing solos but ill give it a try but i end up suiciding cause im doing good but i fall off a ravine or something :P </s> <u5> <s5> <question> <u1> Is pigmen spawning enabled? </s> <u6> <s1> <answer> <u5> Pigmen will spawn in the nether :) </s> <u7> <s6> <question> <u1> When whitelist is off? </s> <u8> <s4> <question> <u1> allies allowed? </s> <u9> <s1> <answer> <u8> No allies </s> <u10> <s7> <appreciation> <u1> I'll be there too :D Thanks in advance for hosting! </s> <u11> <s8> <negativereaction> <u1> So fucking stupid, it said im not whitelisted then its full complete bullshit. </s> <s9> <u11> So fucking stupid, it said im not whitelisted then its full complete bullshit.\",\n",
       "  \"<other> Settle down there, lil' buddy. Plenty more games to play.\"],\n",
       " [\"<u1> <s1> <announcement> <bos> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30 </s> <u2> <s2> <unk> <u1> I'll be there^h^y^p^e </s> <u3> <s3> <unk> <u1> finally a game with nether! </s> <u4> <s4> <elaboration> <u1> I dont like doing solos but ill give it a try but i end up suiciding cause im doing good but i fall off a ravine or something :P </s> <u5> <s5> <question> <u1> Is pigmen spawning enabled? </s> <u6> <s1> <answer> <u5> Pigmen will spawn in the nether :) </s> <u7> <s6> <question> <u1> When whitelist is off? </s> <u8> <s4> <question> <u1> allies allowed? </s> <u9> <s1> <answer> <u8> No allies </s> <u10> <s7> <appreciation> <u1> I'll be there too :D Thanks in advance for hosting! </s> <u11> <s8> <negativereaction> <u1> So fucking stupid, it said im not whitelisted then its full complete bullshit. </s> <u12> <s9> <other> <u11> Settle down there, lil' buddy. Plenty more games to play. </s> <s1> <u11> So fucking stupid, it said im not whitelisted then its full complete bullshit.\",\n",
       "  '<elaboration> You have to join at exactly 15 minutes before match start\\n'],\n",
       " [\"<u1> <s1> <announcement> <bos> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30 </s> <u2> <s2> <unk> <u1> I'll be there^h^y^p^e </s> <u3> <s3> <unk> <u1> finally a game with nether! </s> <u4> <s4> <elaboration> <u1> I dont like doing solos but ill give it a try but i end up suiciding cause im doing good but i fall off a ravine or something :P </s> <u5> <s5> <question> <u1> Is pigmen spawning enabled? </s> <u6> <s1> <answer> <u5> Pigmen will spawn in the nether :) </s> <u7> <s6> <question> <u1> When whitelist is off? </s> <u8> <s4> <question> <u1> allies allowed? </s> <u9> <s1> <answer> <u8> No allies </s> <u10> <s7> <appreciation> <u1> I'll be there too :D Thanks in advance for hosting! </s> <u11> <s8> <negativereaction> <u1> So fucking stupid, it said im not whitelisted then its full complete bullshit. </s> <u12> <s9> <other> <u11> Settle down there, lil' buddy. Plenty more games to play. </s> <u13> <s1> <elaboration> <u11> You have to join at exactly 15 minutes before match start </s> <s10> <u1> [Universal Rules](http://www.reddit.com/r/uhccourtroom/wiki/banguidelines) [Universal Ban List](https://docs.google.com/spreadsheet/ccc?key=0AjACyg1Jc3_GdEhqWU5PTEVHZDVLYWphd2JfaEZXd2c#gid=0) **Notes:** --- **IP:** 31.3.251.181 **Version:** 1.7.4 **Whitelist off:** 15 minutes before start **Game start:** 14:00 UTC **Game length:** 1.5 hours **Endgame:** Meetup at 0,0 **Player Slots:** 30 **Gamemode/Scenario:** FFA **PvP/iPvP:** 2nd day **Stealing:** Yes **Stalking:** No **Towering:** No **GHeads:** Yes **Absorption:** Yes **Nether:** On **Allies:** No **Additional Info:** --- **Server Info:** **Ram:** 2.5GB **Located in:** London **Slots:** 30\",\n",
       "  \"<unk> Bad hosting in my mind Potions weren't nerfed one bit i got 2 hit when i had full prot 2 on kinda upset\"]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_ids = list(set(utter_df.conversation_id.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, test_ids = train_test_split(conversation_ids, test_size=0.15, random_state=5757)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_discourse_tokens(text):\n",
    "    for item in ['<negativereaction>',\n",
    "     '<other>',\n",
    "     '<appreciation>',\n",
    "     '<unk>',\n",
    "     '<elaboration>',\n",
    "     '<answer>',\n",
    "     '<question>',\n",
    "     '<humor>',\n",
    "     '<announcement>',\n",
    "     '<agreement>',\n",
    "     '<disagreement>']:\n",
    "        text = text.replace(item, '')\n",
    "    return text\n",
    "\n",
    "\n",
    "def construct_bart_input(data, save_path, col1='document', col2='summary', drop_rels_context=False, drop_rels_utter=False,\n",
    "                         repl_random=True, repl_prob=0.15):\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    if drop_rels_context:\n",
    "        df[col1] = [re.sub(r'\\s+', ' ', remove_discourse_tokens(el[0])) for el in data]\n",
    "    else:\n",
    "        df[col1] = [re.sub(r'\\s+', ' ', el[0]) for el in data]\n",
    "    if drop_rels_utter:\n",
    "        df[col2] = [re.sub(r'\\s+', ' ', remove_discourse_tokens(el[1])) for el in data]\n",
    "    else:\n",
    "        df[col2] = [re.sub(r'\\s+', ' ', el[1]) for el in data]\n",
    "    df.to_csv(save_path, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8060/8060 [01:15<00:00, 107.42it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "for conv_id in tqdm(train_ids):\n",
    "    X_train.extend(construct_generation_examples(utter_df, conv_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1423/1423 [00:14<00:00, 96.35it/s] \n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "for conv_id in tqdm(test_ids):\n",
    "    X_test.extend(construct_generation_examples(utter_df, conv_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_bart_input(X_train, 'data/train_structure_convokit.csv', col1='context', col2='structure',\n",
    "                     drop_rels_context=False, drop_rels_utter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_bart_input(X_test, 'data/val_structure_convokit.csv', col1='context', col2='structure',\n",
    "                     drop_rels_context=False, drop_rels_utter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_bart_input(X_train, 'data/train_structure_convokit_norelut.csv', col1='context', col2='structure',\n",
    "                     drop_rels_context=False, drop_rels_utter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_bart_input(X_test, 'data/val_structure_convokit_norelut.csv', col1='context', col2='structure',\n",
    "                    drop_rels_context=False, drop_rels_utter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_bart_input(X_train, 'data/train_structure_convokit_norels.csv', col1='context', col2='structure',\n",
    "                     drop_rels_context=True, drop_rels_utter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_bart_input(X_test, 'data/val_structure_convokit_norels.csv', col1='context', col2='structure',\n",
    "                    drop_rels_context=True, drop_rels_utter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate source & target lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_name_or_path = \"facebook/bart-base\"\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name_or_path)\n",
    "model =  BartForConditionalGeneration.from_pretrained(model_name_or_path).to(device) # to check load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_special_tokens = ['<negativereaction>',\n",
    "     '<other>',\n",
    "     '<appreciation>',\n",
    "     '<unk>',\n",
    "     '<elaboration>',\n",
    "     '<answer>',\n",
    "     '<question>',\n",
    "     '<humor>',\n",
    "     '<announcement>',\n",
    "     '<agreement>',\n",
    "     '<disagreement>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_s, max_u = (40, 41)\n",
    "for s in range(1, max_s+1):\n",
    "    additional_special_tokens.append('<s' + str(s) + '>')\n",
    "for u in range(1, max_u+1):\n",
    "    additional_special_tokens.append('<u' + str(u) + '>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens_dict = {'additional_special_tokens': additional_special_tokens,\n",
    "                         'bos_token': '<s>',\n",
    "                         'eos_token': '</s>',\n",
    "                         'unk_token': '<unk>',\n",
    "                         'sep_token': '</s>',\n",
    "                         'pad_token': '<pad>',\n",
    "                         'cls_token': '<s>',\n",
    "                         'mask_token': '<mask>'}\n",
    "\n",
    "with open('data/special_tokens_map_convokit.pkl', 'wb') as f:\n",
    "    pickle.dump(special_tokens_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/special_tokens_map_convokit.pkl', 'rb') as f:\n",
    "    special_tokens_dict = pickle.load(f)\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50265"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50356"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_added_toks + tokenizer.vocab_size # COPY TO WEIGHTS IN MODELING.PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<negativereaction> <other> <appreciation> <elaboration> <answer> <question> <humor> <announcement> <agreement> <disagreement>'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([50265, 50266, 50267, 50268, 50269, 50270, 50271, 50272, 50273, 50274])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens_text = []\n",
    "num_tokens_summ = []\n",
    "for record in tqdm(X_train):\n",
    "    num_tokens_text.append(len(tokenizer.encode(record[0])))\n",
    "    num_tokens_summ.append(len(tokenizer.encode(record[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(887.4763411564917, 575.0, 1166.0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens_text), np.median(num_tokens_text), np.quantile(num_tokens_text, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57.10955272385188, 32.0, 64.0)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens_summ), np.median(num_tokens_summ), np.quantile(num_tokens_summ, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxk3QE9tSjeS"
   },
   "source": [
    "## Train Structure Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "06/18/2022 15:56:24 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "06/18/2022 15:56:24 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=2,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=checkpoints/structure_custom_bart_convokit_bs_1_2_lr_2e5_ep_5_w_30/runs/Jun18_15-56-24_cn-006,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=5.0,\n",
      "optim=OptimizerNames.ADAMW_HF,\n",
      "output_dir=checkpoints/structure_custom_bart_convokit_bs_1_2_lr_2e5_ep_5_w_30,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=1,\n",
      "per_device_train_batch_size=1,\n",
      "predict_with_generate=False,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=checkpoints/structure_custom_bart_convokit_bs_1_2_lr_2e5_ep_5_w_30,\n",
      "save_on_each_node=False,\n",
      "save_steps=80000,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "06/18/2022 15:56:25 - WARNING - datasets.builder - Using custom data configuration default-81207ee423de180e\n",
      "06/18/2022 15:56:25 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "06/18/2022 15:56:25 - INFO - datasets.info - Loading Dataset info from /home/aschernyavskiy/.cache/huggingface/datasets/csv/default-81207ee423de180e/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e\n",
      "06/18/2022 15:56:25 - WARNING - datasets.builder - Reusing dataset csv (/home/aschernyavskiy/.cache/huggingface/datasets/csv/default-81207ee423de180e/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n",
      "06/18/2022 15:56:25 - INFO - datasets.info - Loading Dataset info from /home/aschernyavskiy/.cache/huggingface/datasets/csv/default-81207ee423de180e/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  6.27it/s]\n",
      "[INFO|configuration_utils.py:644] 2022-06-18 15:56:26,340 >> loading configuration file https://huggingface.co/facebook/bart-base/resolve/main/config.json from cache at /home/aschernyavskiy/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.a243ed957122436adb0b8d8e9d20f896f45c174b6324d625ca0a20a84f72a910\n",
      "[INFO|configuration_utils.py:680] 2022-06-18 15:56:26,350 >> Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1771] 2022-06-18 15:56:30,145 >> loading file https://huggingface.co/facebook/bart-base/resolve/main/vocab.json from cache at /home/aschernyavskiy/.cache/huggingface/transformers/43978bdeaa326572886b44fcfed82f932f76571095ce31973e51c3da8ccade7f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "[INFO|tokenization_utils_base.py:1771] 2022-06-18 15:56:30,146 >> loading file https://huggingface.co/facebook/bart-base/resolve/main/merges.txt from cache at /home/aschernyavskiy/.cache/huggingface/transformers/3c167ed8af56e6605eeb794b63a79d65d85e6708c9b04408d41946337030f5cd.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|tokenization_utils_base.py:1771] 2022-06-18 15:56:30,146 >> loading file https://huggingface.co/facebook/bart-base/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1771] 2022-06-18 15:56:30,146 >> loading file https://huggingface.co/facebook/bart-base/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1771] 2022-06-18 15:56:30,146 >> loading file https://huggingface.co/facebook/bart-base/resolve/main/tokenizer_config.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1771] 2022-06-18 15:56:30,146 >> loading file https://huggingface.co/facebook/bart-base/resolve/main/tokenizer.json from cache at /home/aschernyavskiy/.cache/huggingface/transformers/a878fcd69bba037c9b1b227f4213579ae43d0aaa9374e167bc6c5f41b1cfeb30.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
      "[INFO|configuration_utils.py:644] 2022-06-18 15:56:31,010 >> loading configuration file https://huggingface.co/facebook/bart-base/resolve/main/config.json from cache at /home/aschernyavskiy/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.a243ed957122436adb0b8d8e9d20f896f45c174b6324d625ca0a20a84f72a910\n",
      "[INFO|configuration_utils.py:680] 2022-06-18 15:56:31,012 >> Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1427] 2022-06-18 15:56:31,863 >> loading weights file https://huggingface.co/facebook/bart-base/resolve/main/pytorch_model.bin from cache at /home/aschernyavskiy/.cache/huggingface/transformers/486355ec722ef05fd480e999d4c763be56549ae930f6a3742ee721a5d2a05647.f2f355ad2775769afc60592b43a46d72ca548375e3a1d65f381a751e711cbadd\n",
      "CUSTOM BART with class_weight=30.0\n",
      "[INFO|modeling_utils.py:1694] 2022-06-18 15:56:51,171 >> All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:1703] 2022-06-18 15:56:51,171 >> All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "[INFO|tokenization_utils_base.py:888] 2022-06-18 15:56:51,191 >> Assigning ['<negativereaction>', '<other>', '<appreciation>', '<unk>', '<elaboration>', '<answer>', '<question>', '<humor>', '<announcement>', '<agreement>', '<disagreement>', '<s1>', '<s2>', '<s3>', '<s4>', '<s5>', '<s6>', '<s7>', '<s8>', '<s9>', '<s10>', '<s11>', '<s12>', '<s13>', '<s14>', '<s15>', '<s16>', '<s17>', '<s18>', '<s19>', '<s20>', '<s21>', '<s22>', '<s23>', '<s24>', '<s25>', '<s26>', '<s27>', '<s28>', '<s29>', '<s30>', '<s31>', '<s32>', '<s33>', '<s34>', '<s35>', '<s36>', '<s37>', '<s38>', '<s39>', '<s40>', '<u1>', '<u2>', '<u3>', '<u4>', '<u5>', '<u6>', '<u7>', '<u8>', '<u9>', '<u10>', '<u11>', '<u12>', '<u13>', '<u14>', '<u15>', '<u16>', '<u17>', '<u18>', '<u19>', '<u20>', '<u21>', '<u22>', '<u23>', '<u24>', '<u25>', '<u26>', '<u27>', '<u28>', '<u29>', '<u30>', '<u31>', '<u32>', '<u33>', '<u34>', '<u35>', '<u36>', '<u37>', '<u38>', '<u39>', '<u40>', '<u41>'] to the additional_special_tokens key of the tokenizer\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,191 >> Adding <negativereaction> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,191 >> Adding <other> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,191 >> Adding <appreciation> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,191 >> Adding <elaboration> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,192 >> Adding <answer> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,192 >> Adding <question> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,192 >> Adding <humor> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,192 >> Adding <announcement> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,192 >> Adding <agreement> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,192 >> Adding <disagreement> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,192 >> Adding <s1> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,192 >> Adding <s2> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,192 >> Adding <s3> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,192 >> Adding <s4> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,192 >> Adding <s5> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,192 >> Adding <s6> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,192 >> Adding <s7> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,192 >> Adding <s8> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,192 >> Adding <s9> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,192 >> Adding <s10> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,192 >> Adding <s11> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,193 >> Adding <s12> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,193 >> Adding <s13> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,193 >> Adding <s14> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,193 >> Adding <s15> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,193 >> Adding <s16> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,193 >> Adding <s17> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,193 >> Adding <s18> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,193 >> Adding <s19> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,193 >> Adding <s20> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,193 >> Adding <s21> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,193 >> Adding <s22> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,193 >> Adding <s23> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,193 >> Adding <s24> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,193 >> Adding <s25> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,193 >> Adding <s26> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,193 >> Adding <s27> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,193 >> Adding <s28> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,193 >> Adding <s29> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,194 >> Adding <s30> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,194 >> Adding <s31> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,194 >> Adding <s32> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,194 >> Adding <s33> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,194 >> Adding <s34> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,194 >> Adding <s35> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,194 >> Adding <s36> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,194 >> Adding <s37> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,194 >> Adding <s38> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,194 >> Adding <s39> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,194 >> Adding <s40> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,194 >> Adding <u1> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,194 >> Adding <u2> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,194 >> Adding <u3> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,194 >> Adding <u4> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,194 >> Adding <u5> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,194 >> Adding <u6> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,195 >> Adding <u7> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,195 >> Adding <u8> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,195 >> Adding <u9> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,195 >> Adding <u10> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,195 >> Adding <u11> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,195 >> Adding <u12> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,195 >> Adding <u13> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,195 >> Adding <u14> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,195 >> Adding <u15> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,195 >> Adding <u16> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,195 >> Adding <u17> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,195 >> Adding <u18> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,195 >> Adding <u19> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,195 >> Adding <u20> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,195 >> Adding <u21> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,195 >> Adding <u22> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,195 >> Adding <u23> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,196 >> Adding <u24> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,196 >> Adding <u25> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,196 >> Adding <u26> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,196 >> Adding <u27> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,196 >> Adding <u28> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,196 >> Adding <u29> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,196 >> Adding <u30> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,196 >> Adding <u31> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,196 >> Adding <u32> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,196 >> Adding <u33> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,196 >> Adding <u34> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,196 >> Adding <u35> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,196 >> Adding <u36> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,196 >> Adding <u37> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,196 >> Adding <u38> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,196 >> Adding <u39> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,197 >> Adding <u40> to the vocabulary\n",
      "[INFO|tokenization_utils.py:426] 2022-06-18 15:56:51,197 >> Adding <u41> to the vocabulary\n",
      "[INFO|tokenization_utils_base.py:888] 2022-06-18 15:56:51,197 >> Assigning <s> to the bos_token key of the tokenizer\n",
      "[INFO|tokenization_utils_base.py:888] 2022-06-18 15:56:51,197 >> Assigning </s> to the eos_token key of the tokenizer\n",
      "[INFO|tokenization_utils_base.py:888] 2022-06-18 15:56:51,198 >> Assigning <unk> to the unk_token key of the tokenizer\n",
      "[INFO|tokenization_utils_base.py:888] 2022-06-18 15:56:51,198 >> Assigning </s> to the sep_token key of the tokenizer\n",
      "[INFO|tokenization_utils_base.py:888] 2022-06-18 15:56:51,198 >> Assigning <pad> to the pad_token key of the tokenizer\n",
      "[INFO|tokenization_utils_base.py:888] 2022-06-18 15:56:51,199 >> Assigning <s> to the cls_token key of the tokenizer\n",
      "[INFO|tokenization_utils_base.py:888] 2022-06-18 15:56:51,199 >> Assigning <mask> to the mask_token key of the tokenizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/18/2022 15:56:53 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/aschernyavskiy/.cache/huggingface/datasets/csv/default-81207ee423de180e/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-2860775add7b5b92.arrow\n",
      "06/18/2022 15:56:54 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/aschernyavskiy/.cache/huggingface/datasets/csv/default-81207ee423de180e/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-36c53186a7e0ea2f.arrow\n",
      "/home/aschernyavskiy/anaconda3/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "[INFO|trainer.py:1244] 2022-06-18 15:56:57,589 >> ***** Running training *****\n",
      "[INFO|trainer.py:1245] 2022-06-18 15:56:57,589 >>   Num examples = 81984\n",
      "[INFO|trainer.py:1246] 2022-06-18 15:56:57,589 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:1247] 2022-06-18 15:56:57,589 >>   Instantaneous batch size per device = 1\n",
      "[INFO|trainer.py:1248] 2022-06-18 15:56:57,589 >>   Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "[INFO|trainer.py:1249] 2022-06-18 15:56:57,590 >>   Gradient Accumulation steps = 2\n",
      "[INFO|trainer.py:1250] 2022-06-18 15:56:57,590 >>   Total optimization steps = 204960\n",
      "{'loss': 3.5173, 'learning_rate': 1.9951209992193602e-05, 'epoch': 0.01}        \n",
      "{'loss': 3.1564, 'learning_rate': 1.99024199843872e-05, 'epoch': 0.02}          \n",
      "{'loss': 3.1401, 'learning_rate': 1.9853629976580797e-05, 'epoch': 0.04}        \n",
      "{'loss': 3.0509, 'learning_rate': 1.9804839968774398e-05, 'epoch': 0.05}        \n",
      "{'loss': 3.1103, 'learning_rate': 1.9756049960967995e-05, 'epoch': 0.06}        \n",
      "{'loss': 3.0231, 'learning_rate': 1.9707259953161596e-05, 'epoch': 0.07}        \n",
      "{'loss': 2.9271, 'learning_rate': 1.9658469945355194e-05, 'epoch': 0.09}        \n",
      "{'loss': 2.9529, 'learning_rate': 1.960967993754879e-05, 'epoch': 0.1}          \n",
      "{'loss': 2.9432, 'learning_rate': 1.9560889929742392e-05, 'epoch': 0.11}        \n",
      "{'loss': 2.9046, 'learning_rate': 1.951209992193599e-05, 'epoch': 0.12}         \n",
      "{'loss': 2.842, 'learning_rate': 1.946330991412959e-05, 'epoch': 0.13}          \n",
      "{'loss': 2.8393, 'learning_rate': 1.9414519906323187e-05, 'epoch': 0.15}        \n",
      "{'loss': 2.8771, 'learning_rate': 1.9365729898516785e-05, 'epoch': 0.16}        \n",
      "{'loss': 2.8763, 'learning_rate': 1.9316939890710386e-05, 'epoch': 0.17}        \n",
      "{'loss': 2.8776, 'learning_rate': 1.9268149882903983e-05, 'epoch': 0.18}        \n",
      "{'loss': 2.9012, 'learning_rate': 1.921935987509758e-05, 'epoch': 0.2}          \n",
      "{'loss': 2.8715, 'learning_rate': 1.917056986729118e-05, 'epoch': 0.21}         \n",
      "{'loss': 2.8632, 'learning_rate': 1.912177985948478e-05, 'epoch': 0.22}         \n",
      "{'loss': 2.8066, 'learning_rate': 1.907298985167838e-05, 'epoch': 0.23}         \n",
      "{'loss': 2.8345, 'learning_rate': 1.9024199843871977e-05, 'epoch': 0.24}        \n",
      "{'loss': 2.8071, 'learning_rate': 1.8975409836065574e-05, 'epoch': 0.26}        \n",
      "{'loss': 2.8365, 'learning_rate': 1.8926619828259175e-05, 'epoch': 0.27}        \n",
      "{'loss': 2.8319, 'learning_rate': 1.8877829820452772e-05, 'epoch': 0.28}        \n",
      "{'loss': 2.7989, 'learning_rate': 1.8829039812646373e-05, 'epoch': 0.29}        \n",
      "{'loss': 2.7694, 'learning_rate': 1.878024980483997e-05, 'epoch': 0.3}          \n",
      "{'loss': 2.8257, 'learning_rate': 1.8731459797033568e-05, 'epoch': 0.32}        \n",
      "{'loss': 2.8176, 'learning_rate': 1.868266978922717e-05, 'epoch': 0.33}         \n",
      "{'loss': 2.8136, 'learning_rate': 1.8633879781420766e-05, 'epoch': 0.34}        \n",
      "{'loss': 2.7839, 'learning_rate': 1.8585089773614363e-05, 'epoch': 0.35}        \n",
      "{'loss': 2.8414, 'learning_rate': 1.8536299765807964e-05, 'epoch': 0.37}        \n",
      "{'loss': 2.7858, 'learning_rate': 1.848750975800156e-05, 'epoch': 0.38}         \n",
      "{'loss': 2.774, 'learning_rate': 1.8438719750195162e-05, 'epoch': 0.39}         \n",
      "{'loss': 2.7797, 'learning_rate': 1.838992974238876e-05, 'epoch': 0.4}          \n",
      "{'loss': 2.7891, 'learning_rate': 1.8341139734582357e-05, 'epoch': 0.41}        \n",
      "{'loss': 2.7527, 'learning_rate': 1.8292349726775958e-05, 'epoch': 0.43}        \n",
      "{'loss': 2.7508, 'learning_rate': 1.8243559718969555e-05, 'epoch': 0.44}        \n",
      "{'loss': 2.8169, 'learning_rate': 1.8194769711163156e-05, 'epoch': 0.45}        \n",
      "{'loss': 2.7968, 'learning_rate': 1.8145979703356753e-05, 'epoch': 0.46}        \n",
      "{'loss': 2.7862, 'learning_rate': 1.809718969555035e-05, 'epoch': 0.48}         \n",
      "{'loss': 2.7542, 'learning_rate': 1.804839968774395e-05, 'epoch': 0.49}         \n",
      "{'loss': 2.7682, 'learning_rate': 1.7999609679937552e-05, 'epoch': 0.5}         \n",
      "{'loss': 2.7144, 'learning_rate': 1.795081967213115e-05, 'epoch': 0.51}         \n",
      "{'loss': 2.7551, 'learning_rate': 1.7902029664324747e-05, 'epoch': 0.52}        \n",
      "{'loss': 2.7256, 'learning_rate': 1.7853239656518345e-05, 'epoch': 0.54}        \n",
      "{'loss': 2.8341, 'learning_rate': 1.7804449648711945e-05, 'epoch': 0.55}        \n",
      "{'loss': 2.7762, 'learning_rate': 1.7755659640905546e-05, 'epoch': 0.56}        \n",
      "{'loss': 2.7335, 'learning_rate': 1.770686963309914e-05, 'epoch': 0.57}         \n",
      "{'loss': 2.7216, 'learning_rate': 1.765807962529274e-05, 'epoch': 0.59}         \n",
      "{'loss': 2.7668, 'learning_rate': 1.7609289617486342e-05, 'epoch': 0.6}         \n",
      "{'loss': 2.7993, 'learning_rate': 1.756049960967994e-05, 'epoch': 0.61}         \n",
      "{'loss': 2.7041, 'learning_rate': 1.7511709601873537e-05, 'epoch': 0.62}        \n",
      "{'loss': 2.729, 'learning_rate': 1.7462919594067137e-05, 'epoch': 0.63}         \n",
      "{'loss': 2.7381, 'learning_rate': 1.7414129586260735e-05, 'epoch': 0.65}        \n",
      "{'loss': 2.7836, 'learning_rate': 1.7365339578454336e-05, 'epoch': 0.66}        \n",
      "{'loss': 2.722, 'learning_rate': 1.7316549570647933e-05, 'epoch': 0.67}         \n",
      "{'loss': 2.7214, 'learning_rate': 1.726775956284153e-05, 'epoch': 0.68}         \n",
      "{'loss': 2.718, 'learning_rate': 1.721896955503513e-05, 'epoch': 0.7}           \n",
      "{'loss': 2.7256, 'learning_rate': 1.717017954722873e-05, 'epoch': 0.71}         \n",
      "{'loss': 2.6987, 'learning_rate': 1.712138953942233e-05, 'epoch': 0.72}         \n",
      "{'loss': 2.7353, 'learning_rate': 1.7072599531615927e-05, 'epoch': 0.73}        \n",
      "{'loss': 2.7488, 'learning_rate': 1.7023809523809524e-05, 'epoch': 0.74}        \n",
      "{'loss': 2.7561, 'learning_rate': 1.6975019516003125e-05, 'epoch': 0.76}        \n",
      "{'loss': 2.6442, 'learning_rate': 1.6926229508196722e-05, 'epoch': 0.77}        \n",
      "{'loss': 2.675, 'learning_rate': 1.6877439500390323e-05, 'epoch': 0.78}         \n",
      "{'loss': 2.725, 'learning_rate': 1.682864949258392e-05, 'epoch': 0.79}          \n",
      "{'loss': 2.7503, 'learning_rate': 1.6779859484777518e-05, 'epoch': 0.81}        \n",
      "{'loss': 2.7366, 'learning_rate': 1.673106947697112e-05, 'epoch': 0.82}         \n",
      "{'loss': 2.7052, 'learning_rate': 1.6682279469164716e-05, 'epoch': 0.83}        \n",
      "{'loss': 2.6993, 'learning_rate': 1.6633489461358313e-05, 'epoch': 0.84}        \n",
      "{'loss': 2.731, 'learning_rate': 1.6584699453551914e-05, 'epoch': 0.85}         \n",
      "{'loss': 2.7586, 'learning_rate': 1.653590944574551e-05, 'epoch': 0.87}         \n",
      "{'loss': 2.7036, 'learning_rate': 1.6487119437939112e-05, 'epoch': 0.88}        \n",
      "{'loss': 2.7084, 'learning_rate': 1.643832943013271e-05, 'epoch': 0.89}         \n",
      "{'loss': 2.6791, 'learning_rate': 1.6389539422326307e-05, 'epoch': 0.9}         \n",
      "{'loss': 2.7162, 'learning_rate': 1.6340749414519908e-05, 'epoch': 0.91}        \n",
      "{'loss': 2.7079, 'learning_rate': 1.6291959406713505e-05, 'epoch': 0.93}        \n",
      "{'loss': 2.702, 'learning_rate': 1.6243169398907106e-05, 'epoch': 0.94}         \n",
      "{'loss': 2.7625, 'learning_rate': 1.6194379391100704e-05, 'epoch': 0.95}        \n",
      "{'loss': 2.6904, 'learning_rate': 1.61455893832943e-05, 'epoch': 0.96}          \n",
      "{'loss': 2.7003, 'learning_rate': 1.6096799375487902e-05, 'epoch': 0.98}        \n",
      "{'loss': 2.7392, 'learning_rate': 1.60480093676815e-05, 'epoch': 0.99}          \n",
      "{'loss': 2.7331, 'learning_rate': 1.59992193598751e-05, 'epoch': 1.0}           \n",
      "{'loss': 2.5509, 'learning_rate': 1.5950429352068697e-05, 'epoch': 1.01}        \n",
      "{'loss': 2.5378, 'learning_rate': 1.5901639344262295e-05, 'epoch': 1.02}        \n",
      "{'loss': 2.6212, 'learning_rate': 1.5852849336455895e-05, 'epoch': 1.04}        \n",
      "{'loss': 2.5374, 'learning_rate': 1.5804059328649496e-05, 'epoch': 1.05}        \n",
      "{'loss': 2.6221, 'learning_rate': 1.575526932084309e-05, 'epoch': 1.06}         \n",
      "{'loss': 2.5848, 'learning_rate': 1.570647931303669e-05, 'epoch': 1.07}         \n",
      "{'loss': 2.6159, 'learning_rate': 1.5657689305230292e-05, 'epoch': 1.09}        \n",
      "{'loss': 2.5647, 'learning_rate': 1.560889929742389e-05, 'epoch': 1.1}          \n",
      "{'loss': 2.6028, 'learning_rate': 1.5560109289617487e-05, 'epoch': 1.11}        \n",
      "{'loss': 2.5954, 'learning_rate': 1.5511319281811087e-05, 'epoch': 1.12}        \n",
      "{'loss': 2.5476, 'learning_rate': 1.5462529274004685e-05, 'epoch': 1.13}        \n",
      "{'loss': 2.5361, 'learning_rate': 1.5413739266198286e-05, 'epoch': 1.15}        \n",
      "{'loss': 2.6495, 'learning_rate': 1.5364949258391883e-05, 'epoch': 1.16}        \n",
      "{'loss': 2.5815, 'learning_rate': 1.531615925058548e-05, 'epoch': 1.17}         \n",
      "{'loss': 2.5688, 'learning_rate': 1.526736924277908e-05, 'epoch': 1.18}         \n",
      "{'loss': 2.585, 'learning_rate': 1.5218579234972679e-05, 'epoch': 1.2}          \n",
      "{'loss': 2.5995, 'learning_rate': 1.5169789227166278e-05, 'epoch': 1.21}        \n",
      "{'loss': 2.6007, 'learning_rate': 1.5120999219359875e-05, 'epoch': 1.22}        \n",
      "{'loss': 2.5679, 'learning_rate': 1.5072209211553474e-05, 'epoch': 1.23}        \n",
      "{'loss': 2.5651, 'learning_rate': 1.5023419203747073e-05, 'epoch': 1.24}        \n",
      "{'loss': 2.5592, 'learning_rate': 1.4974629195940672e-05, 'epoch': 1.26}        \n",
      "{'loss': 2.5926, 'learning_rate': 1.4925839188134273e-05, 'epoch': 1.27}        \n",
      "{'loss': 2.6338, 'learning_rate': 1.4877049180327869e-05, 'epoch': 1.28}        \n",
      "{'loss': 2.5901, 'learning_rate': 1.4828259172521468e-05, 'epoch': 1.29}        \n",
      "{'loss': 2.5874, 'learning_rate': 1.4779469164715069e-05, 'epoch': 1.31}        \n",
      "{'loss': 2.6226, 'learning_rate': 1.4730679156908668e-05, 'epoch': 1.32}        \n",
      "{'loss': 2.6074, 'learning_rate': 1.4681889149102263e-05, 'epoch': 1.33}        \n",
      "{'loss': 2.5654, 'learning_rate': 1.4633099141295863e-05, 'epoch': 1.34}        \n",
      "{'loss': 2.5936, 'learning_rate': 1.4584309133489463e-05, 'epoch': 1.35}        \n",
      "{'loss': 2.6339, 'learning_rate': 1.4535519125683062e-05, 'epoch': 1.37}        \n",
      "{'loss': 2.5774, 'learning_rate': 1.4486729117876662e-05, 'epoch': 1.38}        \n",
      "{'loss': 2.6138, 'learning_rate': 1.4437939110070259e-05, 'epoch': 1.39}        \n",
      "{'loss': 2.5975, 'learning_rate': 1.4389149102263858e-05, 'epoch': 1.4}         \n",
      "{'loss': 2.5859, 'learning_rate': 1.4340359094457457e-05, 'epoch': 1.41}        \n",
      "{'loss': 2.5158, 'learning_rate': 1.4291569086651056e-05, 'epoch': 1.43}        \n",
      "{'loss': 2.6069, 'learning_rate': 1.4242779078844654e-05, 'epoch': 1.44}        \n",
      "{'loss': 2.5635, 'learning_rate': 1.4193989071038253e-05, 'epoch': 1.45}        \n",
      "{'loss': 2.5783, 'learning_rate': 1.4145199063231852e-05, 'epoch': 1.46}        \n",
      "{'loss': 2.5723, 'learning_rate': 1.4096409055425451e-05, 'epoch': 1.48}        \n",
      "{'loss': 2.5529, 'learning_rate': 1.4047619047619048e-05, 'epoch': 1.49}        \n",
      "{'loss': 2.5612, 'learning_rate': 1.3998829039812647e-05, 'epoch': 1.5}         \n",
      "{'loss': 2.5795, 'learning_rate': 1.3950039032006246e-05, 'epoch': 1.51}        \n",
      "{'loss': 2.5708, 'learning_rate': 1.3901249024199846e-05, 'epoch': 1.52}        \n",
      "{'loss': 2.5584, 'learning_rate': 1.3852459016393445e-05, 'epoch': 1.54}        \n",
      "{'loss': 2.5729, 'learning_rate': 1.3803669008587042e-05, 'epoch': 1.55}        \n",
      "{'loss': 2.6245, 'learning_rate': 1.3754879000780641e-05, 'epoch': 1.56}        \n",
      "{'loss': 2.5937, 'learning_rate': 1.370608899297424e-05, 'epoch': 1.57}         \n",
      "{'loss': 2.5458, 'learning_rate': 1.365729898516784e-05, 'epoch': 1.59}         \n",
      "{'loss': 2.6188, 'learning_rate': 1.3608508977361437e-05, 'epoch': 1.6}         \n",
      "{'loss': 2.5878, 'learning_rate': 1.3559718969555036e-05, 'epoch': 1.61}        \n",
      "{'loss': 2.5735, 'learning_rate': 1.3510928961748635e-05, 'epoch': 1.62}        \n",
      "{'loss': 2.578, 'learning_rate': 1.3462138953942234e-05, 'epoch': 1.63}         \n",
      "{'loss': 2.6338, 'learning_rate': 1.3413348946135833e-05, 'epoch': 1.65}        \n",
      "{'loss': 2.6545, 'learning_rate': 1.336455893832943e-05, 'epoch': 1.66}         \n",
      "{'loss': 2.5789, 'learning_rate': 1.331576893052303e-05, 'epoch': 1.67}         \n",
      "{'loss': 2.5851, 'learning_rate': 1.3266978922716629e-05, 'epoch': 1.68}        \n",
      "{'loss': 2.5243, 'learning_rate': 1.3218188914910228e-05, 'epoch': 1.7}         \n",
      "{'loss': 2.5706, 'learning_rate': 1.3169398907103825e-05, 'epoch': 1.71}        \n",
      "{'loss': 2.5489, 'learning_rate': 1.3120608899297424e-05, 'epoch': 1.72}        \n",
      "{'loss': 2.5915, 'learning_rate': 1.3071818891491023e-05, 'epoch': 1.73}        \n",
      "{'loss': 2.5799, 'learning_rate': 1.3023028883684622e-05, 'epoch': 1.74}        \n",
      "{'loss': 2.6339, 'learning_rate': 1.2974238875878221e-05, 'epoch': 1.76}        \n",
      "{'loss': 2.5662, 'learning_rate': 1.2925448868071819e-05, 'epoch': 1.77}        \n",
      "{'loss': 2.5766, 'learning_rate': 1.2876658860265418e-05, 'epoch': 1.78}        \n",
      "{'loss': 2.5568, 'learning_rate': 1.2827868852459017e-05, 'epoch': 1.79}        \n",
      "{'loss': 2.6304, 'learning_rate': 1.2779078844652618e-05, 'epoch': 1.81}        \n",
      "{'loss': 2.5495, 'learning_rate': 1.2730288836846214e-05, 'epoch': 1.82}        \n",
      "{'loss': 2.6008, 'learning_rate': 1.2681498829039813e-05, 'epoch': 1.83}        \n",
      "{'loss': 2.5652, 'learning_rate': 1.2632708821233413e-05, 'epoch': 1.84}        \n",
      "{'loss': 2.5921, 'learning_rate': 1.2583918813427012e-05, 'epoch': 1.85}        \n",
      "{'loss': 2.6012, 'learning_rate': 1.2535128805620608e-05, 'epoch': 1.87}        \n",
      "{'loss': 2.5434, 'learning_rate': 1.2486338797814207e-05, 'epoch': 1.88}        \n",
      "{'loss': 2.5487, 'learning_rate': 1.2437548790007808e-05, 'epoch': 1.89}        \n",
      "{'loss': 2.5945, 'learning_rate': 1.2388758782201407e-05, 'epoch': 1.9}         \n",
      "{'loss': 2.5522, 'learning_rate': 1.2339968774395006e-05, 'epoch': 1.92}        \n",
      "{'loss': 2.5557, 'learning_rate': 1.2291178766588604e-05, 'epoch': 1.93}        \n",
      "{'loss': 2.5105, 'learning_rate': 1.2242388758782203e-05, 'epoch': 1.94}        \n",
      "{'loss': 2.5699, 'learning_rate': 1.2193598750975802e-05, 'epoch': 1.95}        \n",
      " 39%|████████████▍                   | 80000/204960 [3:30:02<5:14:05,  6.63it/s][INFO|trainer.py:2090] 2022-06-18 19:27:00,542 >> Saving model checkpoint to checkpoints/structure_custom_bart_convokit_bs_1_2_lr_2e5_ep_5_w_30/checkpoint-80000\n",
      "[INFO|configuration_utils.py:430] 2022-06-18 19:27:00,546 >> Configuration saved in checkpoints/structure_custom_bart_convokit_bs_1_2_lr_2e5_ep_5_w_30/checkpoint-80000/config.json\n",
      "[INFO|modeling_utils.py:1074] 2022-06-18 19:27:01,555 >> Model weights saved in checkpoints/structure_custom_bart_convokit_bs_1_2_lr_2e5_ep_5_w_30/checkpoint-80000/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2074] 2022-06-18 19:27:01,714 >> tokenizer config file saved in checkpoints/structure_custom_bart_convokit_bs_1_2_lr_2e5_ep_5_w_30/checkpoint-80000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2080] 2022-06-18 19:27:01,720 >> Special tokens file saved in checkpoints/structure_custom_bart_convokit_bs_1_2_lr_2e5_ep_5_w_30/checkpoint-80000/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2125] 2022-06-18 19:27:01,721 >> added tokens file saved in checkpoints/structure_custom_bart_convokit_bs_1_2_lr_2e5_ep_5_w_30/checkpoint-80000/added_tokens.json\n",
      "{'loss': 2.5271, 'learning_rate': 1.2144808743169401e-05, 'epoch': 1.96}        \n",
      "{'loss': 2.5879, 'learning_rate': 1.2096018735362998e-05, 'epoch': 1.98}        \n",
      "{'loss': 2.5697, 'learning_rate': 1.2047228727556597e-05, 'epoch': 1.99}        \n",
      "{'loss': 2.5912, 'learning_rate': 1.1998438719750196e-05, 'epoch': 2.0}         \n",
      "{'loss': 2.4749, 'learning_rate': 1.1949648711943796e-05, 'epoch': 2.01}        \n",
      "{'loss': 2.4085, 'learning_rate': 1.1900858704137395e-05, 'epoch': 2.02}        \n",
      "{'loss': 2.4552, 'learning_rate': 1.1852068696330992e-05, 'epoch': 2.04}        \n",
      "{'loss': 2.4397, 'learning_rate': 1.1803278688524591e-05, 'epoch': 2.05}        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4582, 'learning_rate': 1.175448868071819e-05, 'epoch': 2.06}         \n",
      "{'loss': 2.4348, 'learning_rate': 1.170569867291179e-05, 'epoch': 2.07}         \n",
      "{'loss': 2.3748, 'learning_rate': 1.1656908665105387e-05, 'epoch': 2.09}        \n",
      "{'loss': 2.4667, 'learning_rate': 1.1608118657298986e-05, 'epoch': 2.1}         \n",
      "{'loss': 2.457, 'learning_rate': 1.1559328649492585e-05, 'epoch': 2.11}         \n",
      "{'loss': 2.4596, 'learning_rate': 1.1510538641686184e-05, 'epoch': 2.12}        \n",
      "{'loss': 2.4409, 'learning_rate': 1.1461748633879783e-05, 'epoch': 2.13}        \n",
      "{'loss': 2.4717, 'learning_rate': 1.141295862607338e-05, 'epoch': 2.15}         \n",
      "{'loss': 2.3646, 'learning_rate': 1.136416861826698e-05, 'epoch': 2.16}         \n",
      "{'loss': 2.5379, 'learning_rate': 1.1315378610460579e-05, 'epoch': 2.17}        \n",
      "{'loss': 2.4362, 'learning_rate': 1.1266588602654178e-05, 'epoch': 2.18}        \n",
      "{'loss': 2.415, 'learning_rate': 1.1217798594847775e-05, 'epoch': 2.2}          \n",
      "{'loss': 2.4194, 'learning_rate': 1.1169008587041374e-05, 'epoch': 2.21}        \n",
      "{'loss': 2.4173, 'learning_rate': 1.1120218579234973e-05, 'epoch': 2.22}        \n",
      "{'loss': 2.4562, 'learning_rate': 1.1071428571428572e-05, 'epoch': 2.23}        \n",
      "{'loss': 2.4336, 'learning_rate': 1.102263856362217e-05, 'epoch': 2.24}         \n",
      "{'loss': 2.4604, 'learning_rate': 1.0973848555815769e-05, 'epoch': 2.26}        \n",
      "{'loss': 2.4753, 'learning_rate': 1.0925058548009368e-05, 'epoch': 2.27}        \n",
      "{'loss': 2.4529, 'learning_rate': 1.0876268540202967e-05, 'epoch': 2.28}        \n",
      "{'loss': 2.4814, 'learning_rate': 1.0827478532396566e-05, 'epoch': 2.29}        \n",
      "{'loss': 2.4359, 'learning_rate': 1.0778688524590164e-05, 'epoch': 2.31}        \n",
      "{'loss': 2.474, 'learning_rate': 1.0729898516783763e-05, 'epoch': 2.32}         \n",
      "{'loss': 2.4175, 'learning_rate': 1.0681108508977362e-05, 'epoch': 2.33}        \n",
      "{'loss': 2.4138, 'learning_rate': 1.0632318501170963e-05, 'epoch': 2.34}        \n",
      "{'loss': 2.4599, 'learning_rate': 1.0583528493364558e-05, 'epoch': 2.35}        \n",
      "{'loss': 2.4574, 'learning_rate': 1.0534738485558157e-05, 'epoch': 2.37}        \n",
      "{'loss': 2.438, 'learning_rate': 1.0485948477751758e-05, 'epoch': 2.38}         \n",
      "{'loss': 2.4414, 'learning_rate': 1.0437158469945357e-05, 'epoch': 2.39}        \n",
      "{'loss': 2.4543, 'learning_rate': 1.0388368462138956e-05, 'epoch': 2.4}         \n",
      "{'loss': 2.4756, 'learning_rate': 1.0339578454332552e-05, 'epoch': 2.42}        \n",
      "{'loss': 2.4424, 'learning_rate': 1.0290788446526153e-05, 'epoch': 2.43}        \n",
      "{'loss': 2.5234, 'learning_rate': 1.0241998438719752e-05, 'epoch': 2.44}        \n",
      "{'loss': 2.4087, 'learning_rate': 1.0193208430913351e-05, 'epoch': 2.45}        \n",
      "{'loss': 2.4927, 'learning_rate': 1.0144418423106948e-05, 'epoch': 2.46}        \n",
      "{'loss': 2.4232, 'learning_rate': 1.0095628415300547e-05, 'epoch': 2.48}        \n",
      "{'loss': 2.4637, 'learning_rate': 1.0046838407494147e-05, 'epoch': 2.49}        \n",
      "{'loss': 2.4304, 'learning_rate': 9.998048399687746e-06, 'epoch': 2.5}          \n",
      "{'loss': 2.4534, 'learning_rate': 9.949258391881343e-06, 'epoch': 2.51}         \n",
      "{'loss': 2.4958, 'learning_rate': 9.900468384074942e-06, 'epoch': 2.52}         \n",
      "{'loss': 2.4969, 'learning_rate': 9.851678376268541e-06, 'epoch': 2.54}         \n",
      "{'loss': 2.4923, 'learning_rate': 9.80288836846214e-06, 'epoch': 2.55}          \n",
      "{'loss': 2.4866, 'learning_rate': 9.754098360655738e-06, 'epoch': 2.56}         \n",
      "{'loss': 2.4818, 'learning_rate': 9.705308352849337e-06, 'epoch': 2.57}         \n",
      "{'loss': 2.4669, 'learning_rate': 9.656518345042936e-06, 'epoch': 2.59}         \n",
      "{'loss': 2.4033, 'learning_rate': 9.607728337236535e-06, 'epoch': 2.6}          \n",
      "{'loss': 2.4451, 'learning_rate': 9.558938329430132e-06, 'epoch': 2.61}         \n",
      "{'loss': 2.4531, 'learning_rate': 9.510148321623731e-06, 'epoch': 2.62}         \n",
      "{'loss': 2.5033, 'learning_rate': 9.461358313817332e-06, 'epoch': 2.63}         \n",
      "{'loss': 2.3878, 'learning_rate': 9.41256830601093e-06, 'epoch': 2.65}          \n",
      "{'loss': 2.4122, 'learning_rate': 9.363778298204529e-06, 'epoch': 2.66}         \n",
      "{'loss': 2.4432, 'learning_rate': 9.314988290398128e-06, 'epoch': 2.67}         \n",
      "{'loss': 2.4225, 'learning_rate': 9.266198282591727e-06, 'epoch': 2.68}         \n",
      "{'loss': 2.3927, 'learning_rate': 9.217408274785324e-06, 'epoch': 2.7}          \n",
      "{'loss': 2.4805, 'learning_rate': 9.168618266978923e-06, 'epoch': 2.71}         \n",
      "{'loss': 2.4352, 'learning_rate': 9.119828259172522e-06, 'epoch': 2.72}         \n",
      "{'loss': 2.4109, 'learning_rate': 9.071038251366122e-06, 'epoch': 2.73}         \n",
      "{'loss': 2.4386, 'learning_rate': 9.022248243559719e-06, 'epoch': 2.74}         \n",
      "{'loss': 2.4739, 'learning_rate': 8.973458235753318e-06, 'epoch': 2.76}         \n",
      "{'loss': 2.5249, 'learning_rate': 8.924668227946917e-06, 'epoch': 2.77}         \n",
      "{'loss': 2.4602, 'learning_rate': 8.875878220140516e-06, 'epoch': 2.78}         \n",
      "{'loss': 2.468, 'learning_rate': 8.827088212334115e-06, 'epoch': 2.79}          \n",
      "{'loss': 2.4863, 'learning_rate': 8.778298204527713e-06, 'epoch': 2.81}         \n",
      "{'loss': 2.4579, 'learning_rate': 8.729508196721312e-06, 'epoch': 2.82}         \n",
      "{'loss': 2.4133, 'learning_rate': 8.680718188914911e-06, 'epoch': 2.83}         \n",
      "{'loss': 2.4841, 'learning_rate': 8.63192818110851e-06, 'epoch': 2.84}          \n",
      "{'loss': 2.442, 'learning_rate': 8.583138173302107e-06, 'epoch': 2.85}          \n",
      "{'loss': 2.4374, 'learning_rate': 8.534348165495706e-06, 'epoch': 2.87}         \n",
      "{'loss': 2.5045, 'learning_rate': 8.485558157689307e-06, 'epoch': 2.88}         \n",
      "{'loss': 2.383, 'learning_rate': 8.436768149882905e-06, 'epoch': 2.89}          \n",
      "{'loss': 2.4435, 'learning_rate': 8.387978142076504e-06, 'epoch': 2.9}          \n",
      "{'loss': 2.4486, 'learning_rate': 8.339188134270103e-06, 'epoch': 2.92}         \n",
      "{'loss': 2.4017, 'learning_rate': 8.290398126463702e-06, 'epoch': 2.93}         \n",
      "{'loss': 2.4776, 'learning_rate': 8.2416081186573e-06, 'epoch': 2.94}           \n",
      "{'loss': 2.4507, 'learning_rate': 8.192818110850898e-06, 'epoch': 2.95}         \n",
      "{'loss': 2.4291, 'learning_rate': 8.144028103044497e-06, 'epoch': 2.96}         \n",
      "{'loss': 2.4428, 'learning_rate': 8.095238095238097e-06, 'epoch': 2.98}         \n",
      "{'loss': 2.5159, 'learning_rate': 8.046448087431694e-06, 'epoch': 2.99}         \n",
      "{'loss': 2.4494, 'learning_rate': 7.997658079625293e-06, 'epoch': 3.0}          \n",
      "{'loss': 2.3038, 'learning_rate': 7.948868071818892e-06, 'epoch': 3.01}         \n",
      "{'loss': 2.2741, 'learning_rate': 7.900078064012491e-06, 'epoch': 3.02}         \n",
      "{'loss': 2.3162, 'learning_rate': 7.85128805620609e-06, 'epoch': 3.04}          \n",
      "{'loss': 2.3662, 'learning_rate': 7.802498048399688e-06, 'epoch': 3.05}         \n",
      "{'loss': 2.323, 'learning_rate': 7.753708040593287e-06, 'epoch': 3.06}          \n",
      "{'loss': 2.3337, 'learning_rate': 7.704918032786886e-06, 'epoch': 3.07}         \n",
      "{'loss': 2.326, 'learning_rate': 7.656128024980485e-06, 'epoch': 3.09}          \n",
      "{'loss': 2.3433, 'learning_rate': 7.607338017174083e-06, 'epoch': 3.1}          \n",
      "{'loss': 2.3234, 'learning_rate': 7.558548009367682e-06, 'epoch': 3.11}         \n",
      "{'loss': 2.3471, 'learning_rate': 7.5097580015612805e-06, 'epoch': 3.12}        \n",
      "{'loss': 2.2896, 'learning_rate': 7.46096799375488e-06, 'epoch': 3.13}          \n",
      "{'loss': 2.3349, 'learning_rate': 7.412177985948479e-06, 'epoch': 3.15}         \n",
      "{'loss': 2.3371, 'learning_rate': 7.363387978142077e-06, 'epoch': 3.16}         \n",
      "{'loss': 2.3552, 'learning_rate': 7.314597970335676e-06, 'epoch': 3.17}         \n",
      "{'loss': 2.3667, 'learning_rate': 7.265807962529274e-06, 'epoch': 3.18}         \n",
      "{'loss': 2.284, 'learning_rate': 7.217017954722873e-06, 'epoch': 3.2}           \n",
      "{'loss': 2.3153, 'learning_rate': 7.168227946916472e-06, 'epoch': 3.21}         \n",
      "{'loss': 2.3274, 'learning_rate': 7.119437939110071e-06, 'epoch': 3.22}         \n",
      "{'loss': 2.3678, 'learning_rate': 7.070647931303669e-06, 'epoch': 3.23}         \n",
      "{'loss': 2.3021, 'learning_rate': 7.021857923497268e-06, 'epoch': 3.24}         \n",
      "{'loss': 2.343, 'learning_rate': 6.973067915690868e-06, 'epoch': 3.26}          \n",
      "{'loss': 2.3182, 'learning_rate': 6.924277907884465e-06, 'epoch': 3.27}         \n",
      "{'loss': 2.309, 'learning_rate': 6.875487900078065e-06, 'epoch': 3.28}          \n",
      "{'loss': 2.353, 'learning_rate': 6.826697892271663e-06, 'epoch': 3.29}          \n",
      "{'loss': 2.2988, 'learning_rate': 6.777907884465263e-06, 'epoch': 3.31}         \n",
      "{'loss': 2.3312, 'learning_rate': 6.729117876658861e-06, 'epoch': 3.32}         \n",
      "{'loss': 2.3727, 'learning_rate': 6.68032786885246e-06, 'epoch': 3.33}          \n",
      "{'loss': 2.3434, 'learning_rate': 6.631537861046058e-06, 'epoch': 3.34}         \n",
      "{'loss': 2.2782, 'learning_rate': 6.582747853239657e-06, 'epoch': 3.35}         \n",
      "{'loss': 2.3545, 'learning_rate': 6.5339578454332556e-06, 'epoch': 3.37}        \n",
      "{'loss': 2.3553, 'learning_rate': 6.485167837626855e-06, 'epoch': 3.38}         \n",
      "{'loss': 2.3082, 'learning_rate': 6.436377829820454e-06, 'epoch': 3.39}         \n",
      "{'loss': 2.3076, 'learning_rate': 6.387587822014052e-06, 'epoch': 3.4}          \n",
      "{'loss': 2.3227, 'learning_rate': 6.338797814207651e-06, 'epoch': 3.42}         \n",
      "{'loss': 2.3171, 'learning_rate': 6.290007806401249e-06, 'epoch': 3.43}         \n",
      "{'loss': 2.3432, 'learning_rate': 6.241217798594848e-06, 'epoch': 3.44}         \n",
      "{'loss': 2.3629, 'learning_rate': 6.192427790788447e-06, 'epoch': 3.45}         \n",
      "{'loss': 2.357, 'learning_rate': 6.143637782982046e-06, 'epoch': 3.46}          \n",
      "{'loss': 2.346, 'learning_rate': 6.094847775175644e-06, 'epoch': 3.48}          \n",
      "{'loss': 2.3182, 'learning_rate': 6.046057767369243e-06, 'epoch': 3.49}         \n",
      "{'loss': 2.3563, 'learning_rate': 5.997267759562842e-06, 'epoch': 3.5}          \n",
      "{'loss': 2.336, 'learning_rate': 5.94847775175644e-06, 'epoch': 3.51}           \n",
      "{'loss': 2.3488, 'learning_rate': 5.89968774395004e-06, 'epoch': 3.53}          \n",
      "{'loss': 2.2875, 'learning_rate': 5.850897736143638e-06, 'epoch': 3.54}         \n",
      "{'loss': 2.3015, 'learning_rate': 5.802107728337238e-06, 'epoch': 3.55}         \n",
      "{'loss': 2.3282, 'learning_rate': 5.753317720530835e-06, 'epoch': 3.56}         \n",
      "{'loss': 2.3478, 'learning_rate': 5.704527712724435e-06, 'epoch': 3.57}         \n",
      "{'loss': 2.3451, 'learning_rate': 5.655737704918033e-06, 'epoch': 3.59}         \n",
      "{'loss': 2.3198, 'learning_rate': 5.606947697111632e-06, 'epoch': 3.6}          \n",
      "{'loss': 2.3811, 'learning_rate': 5.558157689305231e-06, 'epoch': 3.61}         \n",
      "{'loss': 2.3257, 'learning_rate': 5.50936768149883e-06, 'epoch': 3.62}          \n",
      "{'loss': 2.2999, 'learning_rate': 5.460577673692429e-06, 'epoch': 3.63}         \n",
      "{'loss': 2.35, 'learning_rate': 5.411787665886027e-06, 'epoch': 3.65}           \n",
      "{'loss': 2.3101, 'learning_rate': 5.362997658079626e-06, 'epoch': 3.66}         \n",
      "{'loss': 2.3364, 'learning_rate': 5.314207650273224e-06, 'epoch': 3.67}         \n",
      "{'loss': 2.362, 'learning_rate': 5.2654176424668234e-06, 'epoch': 3.68}         \n",
      "{'loss': 2.3665, 'learning_rate': 5.216627634660422e-06, 'epoch': 3.7}          \n",
      "{'loss': 2.3787, 'learning_rate': 5.167837626854021e-06, 'epoch': 3.71}         \n",
      "{'loss': 2.3758, 'learning_rate': 5.119047619047619e-06, 'epoch': 3.72}         \n",
      "{'loss': 2.3335, 'learning_rate': 5.070257611241218e-06, 'epoch': 3.73}         \n",
      "{'loss': 2.321, 'learning_rate': 5.021467603434816e-06, 'epoch': 3.74}          \n",
      "{'loss': 2.3512, 'learning_rate': 4.9726775956284154e-06, 'epoch': 3.76}        \n",
      "{'loss': 2.3706, 'learning_rate': 4.9238875878220145e-06, 'epoch': 3.77}        \n",
      "{'loss': 2.3209, 'learning_rate': 4.875097580015613e-06, 'epoch': 3.78}         \n",
      "{'loss': 2.3503, 'learning_rate': 4.826307572209212e-06, 'epoch': 3.79}         \n",
      "{'loss': 2.3149, 'learning_rate': 4.77751756440281e-06, 'epoch': 3.81}          \n",
      "{'loss': 2.3444, 'learning_rate': 4.72872755659641e-06, 'epoch': 3.82}          \n",
      "{'loss': 2.2822, 'learning_rate': 4.679937548790008e-06, 'epoch': 3.83}         \n",
      "{'loss': 2.2887, 'learning_rate': 4.631147540983607e-06, 'epoch': 3.84}         \n",
      "{'loss': 2.3431, 'learning_rate': 4.582357533177206e-06, 'epoch': 3.85}         \n",
      "{'loss': 2.3554, 'learning_rate': 4.533567525370805e-06, 'epoch': 3.87}         \n",
      "{'loss': 2.2801, 'learning_rate': 4.484777517564403e-06, 'epoch': 3.88}         \n",
      "{'loss': 2.397, 'learning_rate': 4.435987509758002e-06, 'epoch': 3.89}          \n",
      "{'loss': 2.3592, 'learning_rate': 4.3871975019516e-06, 'epoch': 3.9}            \n",
      " 78%|████████████████████████▏      | 160000/204960 [6:59:52<2:07:08,  5.89it/s][INFO|trainer.py:2090] 2022-06-18 22:56:49,859 >> Saving model checkpoint to checkpoints/structure_custom_bart_convokit_bs_1_2_lr_2e5_ep_5_w_30/checkpoint-160000\n",
      "[INFO|configuration_utils.py:430] 2022-06-18 22:56:49,863 >> Configuration saved in checkpoints/structure_custom_bart_convokit_bs_1_2_lr_2e5_ep_5_w_30/checkpoint-160000/config.json\n",
      "[INFO|modeling_utils.py:1074] 2022-06-18 22:56:50,887 >> Model weights saved in checkpoints/structure_custom_bart_convokit_bs_1_2_lr_2e5_ep_5_w_30/checkpoint-160000/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2074] 2022-06-18 22:56:51,030 >> tokenizer config file saved in checkpoints/structure_custom_bart_convokit_bs_1_2_lr_2e5_ep_5_w_30/checkpoint-160000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2080] 2022-06-18 22:56:51,038 >> Special tokens file saved in checkpoints/structure_custom_bart_convokit_bs_1_2_lr_2e5_ep_5_w_30/checkpoint-160000/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2125] 2022-06-18 22:56:51,046 >> added tokens file saved in checkpoints/structure_custom_bart_convokit_bs_1_2_lr_2e5_ep_5_w_30/checkpoint-160000/added_tokens.json\n",
      "{'loss': 2.3129, 'learning_rate': 4.338407494145199e-06, 'epoch': 3.92}         \n",
      "{'loss': 2.3167, 'learning_rate': 4.289617486338798e-06, 'epoch': 3.93}         \n",
      "{'loss': 2.3531, 'learning_rate': 4.2408274785323975e-06, 'epoch': 3.94}        \n",
      "{'loss': 2.3335, 'learning_rate': 4.192037470725996e-06, 'epoch': 3.95}         \n",
      "{'loss': 2.3295, 'learning_rate': 4.143247462919595e-06, 'epoch': 3.96}         \n",
      "{'loss': 2.3161, 'learning_rate': 4.094457455113193e-06, 'epoch': 3.98}         \n",
      "{'loss': 2.3023, 'learning_rate': 4.045667447306792e-06, 'epoch': 3.99}         \n",
      "{'loss': 2.2571, 'learning_rate': 3.9968774395003904e-06, 'epoch': 4.0}         \n",
      "{'loss': 2.2206, 'learning_rate': 3.9480874316939895e-06, 'epoch': 4.01}        \n",
      "{'loss': 2.223, 'learning_rate': 3.899297423887588e-06, 'epoch': 4.03}          \n",
      "{'loss': 2.2112, 'learning_rate': 3.850507416081187e-06, 'epoch': 4.04}         \n",
      "{'loss': 2.1906, 'learning_rate': 3.8017174082747855e-06, 'epoch': 4.05}        \n",
      "{'loss': 2.2157, 'learning_rate': 3.752927400468384e-06, 'epoch': 4.06}         \n",
      "{'loss': 2.2669, 'learning_rate': 3.7041373926619833e-06, 'epoch': 4.07}        \n",
      "{'loss': 2.2451, 'learning_rate': 3.655347384855582e-06, 'epoch': 4.09}         \n",
      "{'loss': 2.2244, 'learning_rate': 3.6065573770491806e-06, 'epoch': 4.1}         \n",
      "{'loss': 2.3364, 'learning_rate': 3.5577673692427793e-06, 'epoch': 4.11}        \n",
      "{'loss': 2.2251, 'learning_rate': 3.508977361436378e-06, 'epoch': 4.12}         \n",
      "{'loss': 2.2644, 'learning_rate': 3.4601873536299766e-06, 'epoch': 4.13}        \n",
      "{'loss': 2.2406, 'learning_rate': 3.4113973458235757e-06, 'epoch': 4.15}        \n",
      "{'loss': 2.2187, 'learning_rate': 3.3626073380171744e-06, 'epoch': 4.16}        \n",
      "{'loss': 2.2291, 'learning_rate': 3.313817330210773e-06, 'epoch': 4.17}         \n",
      "{'loss': 2.2079, 'learning_rate': 3.2650273224043717e-06, 'epoch': 4.18}        \n",
      "{'loss': 2.1699, 'learning_rate': 3.216237314597971e-06, 'epoch': 4.2}          \n",
      "{'loss': 2.2114, 'learning_rate': 3.1674473067915695e-06, 'epoch': 4.21}        \n",
      "{'loss': 2.1839, 'learning_rate': 3.118657298985168e-06, 'epoch': 4.22}         \n",
      "{'loss': 2.2491, 'learning_rate': 3.069867291178767e-06, 'epoch': 4.23}         \n",
      "{'loss': 2.2049, 'learning_rate': 3.0210772833723655e-06, 'epoch': 4.24}        \n",
      "{'loss': 2.1998, 'learning_rate': 2.972287275565964e-06, 'epoch': 4.26}         \n",
      "{'loss': 2.2094, 'learning_rate': 2.923497267759563e-06, 'epoch': 4.27}         \n",
      "{'loss': 2.2244, 'learning_rate': 2.874707259953162e-06, 'epoch': 4.28}         \n",
      "{'loss': 2.2227, 'learning_rate': 2.8259172521467606e-06, 'epoch': 4.29}        \n",
      "{'loss': 2.2197, 'learning_rate': 2.7771272443403592e-06, 'epoch': 4.31}        \n",
      "{'loss': 2.2175, 'learning_rate': 2.7283372365339583e-06, 'epoch': 4.32}        \n",
      "{'loss': 2.2251, 'learning_rate': 2.679547228727557e-06, 'epoch': 4.33}         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2312, 'learning_rate': 2.6307572209211556e-06, 'epoch': 4.34}        \n",
      "{'loss': 2.2005, 'learning_rate': 2.5819672131147543e-06, 'epoch': 4.35}        \n",
      "{'loss': 2.1928, 'learning_rate': 2.533177205308353e-06, 'epoch': 4.37}         \n",
      "{'loss': 2.2766, 'learning_rate': 2.4843871975019516e-06, 'epoch': 4.38}        \n",
      "{'loss': 2.2493, 'learning_rate': 2.4355971896955503e-06, 'epoch': 4.39}        \n",
      "{'loss': 2.2079, 'learning_rate': 2.386807181889149e-06, 'epoch': 4.4}          \n",
      "{'loss': 2.2284, 'learning_rate': 2.338017174082748e-06, 'epoch': 4.42}         \n",
      "{'loss': 2.2553, 'learning_rate': 2.2892271662763467e-06, 'epoch': 4.43}        \n",
      "{'loss': 2.2131, 'learning_rate': 2.2404371584699454e-06, 'epoch': 4.44}        \n",
      "{'loss': 2.2212, 'learning_rate': 2.191647150663544e-06, 'epoch': 4.45}         \n",
      "{'loss': 2.2558, 'learning_rate': 2.1428571428571427e-06, 'epoch': 4.46}        \n",
      "{'loss': 2.2216, 'learning_rate': 2.094067135050742e-06, 'epoch': 4.48}         \n",
      "{'loss': 2.2236, 'learning_rate': 2.0452771272443405e-06, 'epoch': 4.49}        \n",
      "{'loss': 2.2065, 'learning_rate': 1.996487119437939e-06, 'epoch': 4.5}          \n",
      "{'loss': 2.2329, 'learning_rate': 1.947697111631538e-06, 'epoch': 4.51}         \n",
      "{'loss': 2.1758, 'learning_rate': 1.8989071038251367e-06, 'epoch': 4.53}        \n",
      "{'loss': 2.2692, 'learning_rate': 1.8501170960187356e-06, 'epoch': 4.54}        \n",
      "{'loss': 2.1994, 'learning_rate': 1.8013270882123342e-06, 'epoch': 4.55}        \n",
      "{'loss': 2.2309, 'learning_rate': 1.752537080405933e-06, 'epoch': 4.56}         \n",
      "{'loss': 2.202, 'learning_rate': 1.7037470725995318e-06, 'epoch': 4.57}         \n",
      "{'loss': 2.2644, 'learning_rate': 1.6549570647931305e-06, 'epoch': 4.59}        \n",
      "{'loss': 2.2208, 'learning_rate': 1.6061670569867293e-06, 'epoch': 4.6}         \n",
      "{'loss': 2.2052, 'learning_rate': 1.557377049180328e-06, 'epoch': 4.61}         \n",
      "{'loss': 2.2543, 'learning_rate': 1.5085870413739267e-06, 'epoch': 4.62}        \n",
      "{'loss': 2.2376, 'learning_rate': 1.4597970335675255e-06, 'epoch': 4.64}        \n",
      "{'loss': 2.1861, 'learning_rate': 1.4110070257611242e-06, 'epoch': 4.65}        \n",
      "{'loss': 2.2393, 'learning_rate': 1.362217017954723e-06, 'epoch': 4.66}         \n",
      "{'loss': 2.193, 'learning_rate': 1.3134270101483218e-06, 'epoch': 4.67}         \n",
      "{'loss': 2.1972, 'learning_rate': 1.2646370023419204e-06, 'epoch': 4.68}        \n",
      "{'loss': 2.2771, 'learning_rate': 1.215846994535519e-06, 'epoch': 4.7}          \n",
      "{'loss': 2.2067, 'learning_rate': 1.167056986729118e-06, 'epoch': 4.71}         \n",
      " 94%|███████████████████████████████  | 193087/204960 [8:32:12<32:13,  6.14it/s]"
     ]
    }
   ],
   "source": [
    "# change special tokens map path in run_summarization.py\n",
    "!CUDA_VISIBLE_DEVICES=0 python custom_bart_scripts_weights/run_summarization.py \\\n",
    "    --model_name_or_path=\"facebook/bart-base\" \\\n",
    "    --train_file=\"data/train_structure_convokit.csv\" \\\n",
    "    --validation_file=\"data/val_structure_convokit.csv\" \\\n",
    "    --text_column=\"context\" \\\n",
    "    --summary_column=\"structure\" \\\n",
    "    --max_source_length=1024 \\\n",
    "    --max_target_length=64 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --per_device_train_batch_size=1 \\\n",
    "    --per_device_eval_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=2 \\\n",
    "    --learning_rate=2e-5 \\\n",
    "    --class_weights=30 \\\n",
    "    --save_steps=80000 \\\n",
    "    --num_train_epochs=5 \\\n",
    "    --output_dir=\"checkpoints/structure_custom_bart_convokit_bs_1_2_lr_2e5_ep_5_w_30\" \\\n",
    "    --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "#model_name_or_path = 'checkpoints/structure_custom_bart_convokit_bs_1_2_lr_2e5_ep_5_noisy_0.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = 'checkpoints/structure_custom_bart_convokit_bs_1_2_lr_2e5_ep_5_w_100_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained(model_name_or_path)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name_or_path).train(False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_top(text, num_beams=4,  max_source_len=1024, max_target_length=64, top_k=50, top_p=1):\n",
    "    inputs = tokenizer([text], max_length=max_source_len, return_tensors=\"pt\", truncation=True, padding = False).to(device)\n",
    "    summary_ids = model.generate(inputs[\"input_ids\"], do_sample=True,num_beams=num_beams,\n",
    "                                 max_length=max_target_length, top_k=top_k, top_p=top_p)\n",
    "    pred = tokenizer.batch_decode(summary_ids, clean_up_tokenization_spaces=False)[0]\n",
    "    pred = re.sub(r'\\s+', ' ', pred).replace('</s>', '').replace('<s>', '').strip()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data/val_structure_convokit.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data['context'].values\n",
    "y_test = test_data['structure'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = 13\n",
    "X_test[k], y_test[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_top(X_test[19], top_k=50, num_beams=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i, text in tqdm(enumerate(X_test), total=len(X_test)):\n",
    "    try:\n",
    "        preds.append([text, generate_top(text, top_k=50, num_beams=1)])\n",
    "    except:\n",
    "        print(i)\n",
    "        preds.append([text, 'err'])\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predictions/{}.pkl'.format(model_name_or_path.replace('checkpoints/', '')), 'wb') as f:\n",
    "    pickle.dump([X_test, preds], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
